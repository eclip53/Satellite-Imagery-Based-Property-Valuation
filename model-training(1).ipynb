{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":14426395,"sourceType":"datasetVersion","datasetId":9214532},{"sourceId":14426573,"sourceType":"datasetVersion","datasetId":9214639},{"sourceId":14426894,"sourceType":"datasetVersion","datasetId":9214870}],"dockerImageVersionId":31236,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport xgboost as xgb\nfrom sklearn.model_selection import train_test_split\n\n# 1. Loading the Data\ndata = np.load('/kaggle/input/data-for-model-training-and-testing/dataset.npz')\nids_df = pd.read_csv('/kaggle/input/data-for-model-training-and-testing/test_ids.csv')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2026-01-08T05:25:12.140588Z","iopub.execute_input":"2026-01-08T05:25:12.141325Z","iopub.status.idle":"2026-01-08T05:25:12.161853Z","shell.execute_reply.started":"2026-01-08T05:25:12.141296Z","shell.execute_reply":"2026-01-08T05:25:12.161328Z"}},"outputs":[],"execution_count":23},{"cell_type":"markdown","source":"# Model Training - Tabular Data","metadata":{}},{"cell_type":"code","source":"X_train_full = data['X_train']\ny_train_full = data['y_train']\nX_test_submit = data['x_test']  # This is for the final submission (unseen data)\n\n# 2.Local Validation Set\n# We hold back 20% of our training data to measure accuracy\nX_train, X_val, y_train, y_val = train_test_split(\n    X_train_full, y_train_full, \n    test_size=0.2, \n    random_state=42\n)\n\nprint(f\"Training on:   {X_train.shape} samples\")\nprint(f\"Validating on: {X_val.shape} samples\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T05:25:13.731774Z","iopub.execute_input":"2026-01-08T05:25:13.732108Z","iopub.status.idle":"2026-01-08T05:25:13.747809Z","shell.execute_reply.started":"2026-01-08T05:25:13.732081Z","shell.execute_reply":"2026-01-08T05:25:13.747049Z"}},"outputs":[{"name":"stdout","text":"Training on:   (12967, 18) samples\nValidating on: (3242, 18) samples\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"# 3. Initialize the Model\nmodel = xgb.XGBRegressor(\n    n_estimators=1000,\n    learning_rate=0.05,\n    max_depth=6,\n    subsample=0.8,\n    colsample_bytree=0.8,\n    n_jobs=-1,            # Use all CPU cores\n    random_state=42\n)\n\n# 4. Train with Early Stopping\n# This automatically stops if validation error stops dropping\neval_set = [(X_train, y_train), (X_val, y_val)]\n\nmodel.fit(\n    X_train, y_train,\n    eval_set=eval_set,\n    verbose=100  # Print progress every 100 rounds\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T05:25:14.696377Z","iopub.execute_input":"2026-01-08T05:25:14.697081Z","iopub.status.idle":"2026-01-08T05:25:16.621445Z","shell.execute_reply.started":"2026-01-08T05:25:14.697047Z","shell.execute_reply":"2026-01-08T05:25:16.620815Z"}},"outputs":[{"name":"stdout","text":"[0]\tvalidation_0-rmse:349592.54685\tvalidation_1-rmse:343051.15282\n[100]\tvalidation_0-rmse:91508.42621\tvalidation_1-rmse:125263.61970\n[200]\tvalidation_0-rmse:74581.65104\tvalidation_1-rmse:119568.82088\n[300]\tvalidation_0-rmse:65484.51287\tvalidation_1-rmse:117907.76656\n[400]\tvalidation_0-rmse:58709.92005\tvalidation_1-rmse:117363.64951\n[500]\tvalidation_0-rmse:53549.87199\tvalidation_1-rmse:116918.42573\n[600]\tvalidation_0-rmse:49414.45755\tvalidation_1-rmse:116785.66793\n[700]\tvalidation_0-rmse:45467.44412\tvalidation_1-rmse:116654.85252\n[800]\tvalidation_0-rmse:42127.67437\tvalidation_1-rmse:116590.62021\n[900]\tvalidation_0-rmse:39161.68013\tvalidation_1-rmse:116496.44823\n[999]\tvalidation_0-rmse:36537.00487\tvalidation_1-rmse:116523.57755\n","output_type":"stream"},{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"XGBRegressor(base_score=None, booster=None, callbacks=None,\n             colsample_bylevel=None, colsample_bynode=None,\n             colsample_bytree=0.8, device=None, early_stopping_rounds=None,\n             enable_categorical=False, eval_metric=None, feature_types=None,\n             feature_weights=None, gamma=None, grow_policy=None,\n             importance_type=None, interaction_constraints=None,\n             learning_rate=0.05, max_bin=None, max_cat_threshold=None,\n             max_cat_to_onehot=None, max_delta_step=None, max_depth=6,\n             max_leaves=None, min_child_weight=None, missing=nan,\n             monotone_constraints=None, multi_strategy=None, n_estimators=1000,\n             n_jobs=-1, num_parallel_tree=None, ...)","text/html":"<style>#sk-container-id-3 {\n  /* Definition of color scheme common for light and dark mode */\n  --sklearn-color-text: #000;\n  --sklearn-color-text-muted: #666;\n  --sklearn-color-line: gray;\n  /* Definition of color scheme for unfitted estimators */\n  --sklearn-color-unfitted-level-0: #fff5e6;\n  --sklearn-color-unfitted-level-1: #f6e4d2;\n  --sklearn-color-unfitted-level-2: #ffe0b3;\n  --sklearn-color-unfitted-level-3: chocolate;\n  /* Definition of color scheme for fitted estimators */\n  --sklearn-color-fitted-level-0: #f0f8ff;\n  --sklearn-color-fitted-level-1: #d4ebff;\n  --sklearn-color-fitted-level-2: #b3dbfd;\n  --sklearn-color-fitted-level-3: cornflowerblue;\n\n  /* Specific color for light theme */\n  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n  --sklearn-color-icon: #696969;\n\n  @media (prefers-color-scheme: dark) {\n    /* Redefinition of color scheme for dark theme */\n    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n    --sklearn-color-icon: #878787;\n  }\n}\n\n#sk-container-id-3 {\n  color: var(--sklearn-color-text);\n}\n\n#sk-container-id-3 pre {\n  padding: 0;\n}\n\n#sk-container-id-3 input.sk-hidden--visually {\n  border: 0;\n  clip: rect(1px 1px 1px 1px);\n  clip: rect(1px, 1px, 1px, 1px);\n  height: 1px;\n  margin: -1px;\n  overflow: hidden;\n  padding: 0;\n  position: absolute;\n  width: 1px;\n}\n\n#sk-container-id-3 div.sk-dashed-wrapped {\n  border: 1px dashed var(--sklearn-color-line);\n  margin: 0 0.4em 0.5em 0.4em;\n  box-sizing: border-box;\n  padding-bottom: 0.4em;\n  background-color: var(--sklearn-color-background);\n}\n\n#sk-container-id-3 div.sk-container {\n  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n     but bootstrap.min.css set `[hidden] { display: none !important; }`\n     so we also need the `!important` here to be able to override the\n     default hidden behavior on the sphinx rendered scikit-learn.org.\n     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n  display: inline-block !important;\n  position: relative;\n}\n\n#sk-container-id-3 div.sk-text-repr-fallback {\n  display: none;\n}\n\ndiv.sk-parallel-item,\ndiv.sk-serial,\ndiv.sk-item {\n  /* draw centered vertical line to link estimators */\n  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n  background-size: 2px 100%;\n  background-repeat: no-repeat;\n  background-position: center center;\n}\n\n/* Parallel-specific style estimator block */\n\n#sk-container-id-3 div.sk-parallel-item::after {\n  content: \"\";\n  width: 100%;\n  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n  flex-grow: 1;\n}\n\n#sk-container-id-3 div.sk-parallel {\n  display: flex;\n  align-items: stretch;\n  justify-content: center;\n  background-color: var(--sklearn-color-background);\n  position: relative;\n}\n\n#sk-container-id-3 div.sk-parallel-item {\n  display: flex;\n  flex-direction: column;\n}\n\n#sk-container-id-3 div.sk-parallel-item:first-child::after {\n  align-self: flex-end;\n  width: 50%;\n}\n\n#sk-container-id-3 div.sk-parallel-item:last-child::after {\n  align-self: flex-start;\n  width: 50%;\n}\n\n#sk-container-id-3 div.sk-parallel-item:only-child::after {\n  width: 0;\n}\n\n/* Serial-specific style estimator block */\n\n#sk-container-id-3 div.sk-serial {\n  display: flex;\n  flex-direction: column;\n  align-items: center;\n  background-color: var(--sklearn-color-background);\n  padding-right: 1em;\n  padding-left: 1em;\n}\n\n\n/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\nclickable and can be expanded/collapsed.\n- Pipeline and ColumnTransformer use this feature and define the default style\n- Estimators will overwrite some part of the style using the `sk-estimator` class\n*/\n\n/* Pipeline and ColumnTransformer style (default) */\n\n#sk-container-id-3 div.sk-toggleable {\n  /* Default theme specific background. It is overwritten whether we have a\n  specific estimator or a Pipeline/ColumnTransformer */\n  background-color: var(--sklearn-color-background);\n}\n\n/* Toggleable label */\n#sk-container-id-3 label.sk-toggleable__label {\n  cursor: pointer;\n  display: flex;\n  width: 100%;\n  margin-bottom: 0;\n  padding: 0.5em;\n  box-sizing: border-box;\n  text-align: center;\n  align-items: start;\n  justify-content: space-between;\n  gap: 0.5em;\n}\n\n#sk-container-id-3 label.sk-toggleable__label .caption {\n  font-size: 0.6rem;\n  font-weight: lighter;\n  color: var(--sklearn-color-text-muted);\n}\n\n#sk-container-id-3 label.sk-toggleable__label-arrow:before {\n  /* Arrow on the left of the label */\n  content: \"‚ñ∏\";\n  float: left;\n  margin-right: 0.25em;\n  color: var(--sklearn-color-icon);\n}\n\n#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {\n  color: var(--sklearn-color-text);\n}\n\n/* Toggleable content - dropdown */\n\n#sk-container-id-3 div.sk-toggleable__content {\n  max-height: 0;\n  max-width: 0;\n  overflow: hidden;\n  text-align: left;\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-3 div.sk-toggleable__content.fitted {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n#sk-container-id-3 div.sk-toggleable__content pre {\n  margin: 0.2em;\n  border-radius: 0.25em;\n  color: var(--sklearn-color-text);\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-3 div.sk-toggleable__content.fitted pre {\n  /* unfitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n  /* Expand drop-down */\n  max-height: 200px;\n  max-width: 100%;\n  overflow: auto;\n}\n\n#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n  content: \"‚ñæ\";\n}\n\n/* Pipeline/ColumnTransformer-specific style */\n\n#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-3 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Estimator-specific style */\n\n/* Colorize estimator box */\n#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-3 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n#sk-container-id-3 div.sk-label label.sk-toggleable__label,\n#sk-container-id-3 div.sk-label label {\n  /* The background is the default theme color */\n  color: var(--sklearn-color-text-on-default-background);\n}\n\n/* On hover, darken the color of the background */\n#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n/* Label box, darken color on hover, fitted */\n#sk-container-id-3 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Estimator label */\n\n#sk-container-id-3 div.sk-label label {\n  font-family: monospace;\n  font-weight: bold;\n  display: inline-block;\n  line-height: 1.2em;\n}\n\n#sk-container-id-3 div.sk-label-container {\n  text-align: center;\n}\n\n/* Estimator-specific */\n#sk-container-id-3 div.sk-estimator {\n  font-family: monospace;\n  border: 1px dotted var(--sklearn-color-border-box);\n  border-radius: 0.25em;\n  box-sizing: border-box;\n  margin-bottom: 0.5em;\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-3 div.sk-estimator.fitted {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n/* on hover */\n#sk-container-id-3 div.sk-estimator:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-3 div.sk-estimator.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Specification for estimator info (e.g. \"i\" and \"?\") */\n\n/* Common style for \"i\" and \"?\" */\n\n.sk-estimator-doc-link,\na:link.sk-estimator-doc-link,\na:visited.sk-estimator-doc-link {\n  float: right;\n  font-size: smaller;\n  line-height: 1em;\n  font-family: monospace;\n  background-color: var(--sklearn-color-background);\n  border-radius: 1em;\n  height: 1em;\n  width: 1em;\n  text-decoration: none !important;\n  margin-left: 0.5em;\n  text-align: center;\n  /* unfitted */\n  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n  color: var(--sklearn-color-unfitted-level-1);\n}\n\n.sk-estimator-doc-link.fitted,\na:link.sk-estimator-doc-link.fitted,\na:visited.sk-estimator-doc-link.fitted {\n  /* fitted */\n  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n  color: var(--sklearn-color-fitted-level-1);\n}\n\n/* On hover */\ndiv.sk-estimator:hover .sk-estimator-doc-link:hover,\n.sk-estimator-doc-link:hover,\ndiv.sk-label-container:hover .sk-estimator-doc-link:hover,\n.sk-estimator-doc-link:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\ndiv.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n.sk-estimator-doc-link.fitted:hover,\ndiv.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n.sk-estimator-doc-link.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\n/* Span, style for the box shown on hovering the info icon */\n.sk-estimator-doc-link span {\n  display: none;\n  z-index: 9999;\n  position: relative;\n  font-weight: normal;\n  right: .2ex;\n  padding: .5ex;\n  margin: .5ex;\n  width: min-content;\n  min-width: 20ex;\n  max-width: 50ex;\n  color: var(--sklearn-color-text);\n  box-shadow: 2pt 2pt 4pt #999;\n  /* unfitted */\n  background: var(--sklearn-color-unfitted-level-0);\n  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n}\n\n.sk-estimator-doc-link.fitted span {\n  /* fitted */\n  background: var(--sklearn-color-fitted-level-0);\n  border: var(--sklearn-color-fitted-level-3);\n}\n\n.sk-estimator-doc-link:hover span {\n  display: block;\n}\n\n/* \"?\"-specific style due to the `<a>` HTML tag */\n\n#sk-container-id-3 a.estimator_doc_link {\n  float: right;\n  font-size: 1rem;\n  line-height: 1em;\n  font-family: monospace;\n  background-color: var(--sklearn-color-background);\n  border-radius: 1rem;\n  height: 1rem;\n  width: 1rem;\n  text-decoration: none;\n  /* unfitted */\n  color: var(--sklearn-color-unfitted-level-1);\n  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n}\n\n#sk-container-id-3 a.estimator_doc_link.fitted {\n  /* fitted */\n  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n  color: var(--sklearn-color-fitted-level-1);\n}\n\n/* On hover */\n#sk-container-id-3 a.estimator_doc_link:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\n#sk-container-id-3 a.estimator_doc_link.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-3);\n}\n</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n             colsample_bylevel=None, colsample_bynode=None,\n             colsample_bytree=0.8, device=None, early_stopping_rounds=None,\n             enable_categorical=False, eval_metric=None, feature_types=None,\n             feature_weights=None, gamma=None, grow_policy=None,\n             importance_type=None, interaction_constraints=None,\n             learning_rate=0.05, max_bin=None, max_cat_threshold=None,\n             max_cat_to_onehot=None, max_delta_step=None, max_depth=6,\n             max_leaves=None, min_child_weight=None, missing=nan,\n             monotone_constraints=None, multi_strategy=None, n_estimators=1000,\n             n_jobs=-1, num_parallel_tree=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>XGBRegressor</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor\">?<span>Documentation for XGBRegressor</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n             colsample_bylevel=None, colsample_bynode=None,\n             colsample_bytree=0.8, device=None, early_stopping_rounds=None,\n             enable_categorical=False, eval_metric=None, feature_types=None,\n             feature_weights=None, gamma=None, grow_policy=None,\n             importance_type=None, interaction_constraints=None,\n             learning_rate=0.05, max_bin=None, max_cat_threshold=None,\n             max_cat_to_onehot=None, max_delta_step=None, max_depth=6,\n             max_leaves=None, min_child_weight=None, missing=nan,\n             monotone_constraints=None, multi_strategy=None, n_estimators=1000,\n             n_jobs=-1, num_parallel_tree=None, ...)</pre></div> </div></div></div></div>"},"metadata":{}}],"execution_count":25},{"cell_type":"code","source":"from sklearn.metrics import mean_squared_error, r2_score\n\n# 1. Check Local Accuracy (Validation Set)\nval_predictions = model.predict(X_val)\n\n# Calculate Metrics\nmse = mean_squared_error(y_val, val_predictions)\nrmse = np.sqrt(mse)\nr2 = r2_score(y_val, val_predictions)\n\nprint(\"=\"*40)\nprint(f\"MODEL PERFORMANCE (XGBoost)\")\nprint(f\"Validation RMSE:     ${rmse:,.2f}\")\nprint(f\"Validation R¬≤ Score: {r2:.4f}\")\nprint(\"=\"*40)\n\n# Interpretation\nprint(f\"This means your model explains {r2*100:.2f}% of the price variation.\")\nprint(f\"On average, predictions are off by approx ${rmse:,.0f}.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T05:25:21.375329Z","iopub.execute_input":"2026-01-08T05:25:21.376079Z","iopub.status.idle":"2026-01-08T05:25:21.435505Z","shell.execute_reply.started":"2026-01-08T05:25:21.376050Z","shell.execute_reply":"2026-01-08T05:25:21.434774Z"}},"outputs":[{"name":"stdout","text":"========================================\nMODEL PERFORMANCE (XGBoost)\nValidation RMSE:     $116,523.57\nValidation R¬≤ Score: 0.8918\n========================================\nThis means your model explains 89.18% of the price variation.\nOn average, predictions are off by approx $116,524.\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torchvision.models as models\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import r2_score\nfrom PIL import Image\nimport os\nimport time\n\n# ==========================================\n# 1. CONFIGURATION & PATHS\n# ==========================================\nDEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nBATCH_SIZE = 32\nLEARNING_RATE = 1e-4\nEPOCHS = 20\n\n# Paths (Updated based on your inputs)\nIMAGE_DIR = '/kaggle/input/image-data'\nPROCESSED_DATA_PATH = '/kaggle/input/data-for-model-training-and-testing/dataset.npz'\nTEST_IDS_PATH = '/kaggle/input/data-for-model-training-and-testing/test_ids.csv'\n# Note: Double check this path if it fails. It might be 'train.xlsx'\nORIGINAL_DATA_PATH = '/kaggle/input/dataset-for-model/train(1).xlsx' \n\nprint(f\"üöÄ Running on {DEVICE}\")\n\n# ==========================================\n# 2. DATA LOADING & ALIGNMENT\n# ==========================================\nprint(\"\\n--- Step 1: Loading Data ---\")\n\n# A. Load Numerical Data\ndata = np.load(PROCESSED_DATA_PATH)\nX_train_full = data['X_train']  # Check casing if error (e.g. 'X_train' vs 'x_train')\ny_train_full = data['y_train']\nX_test_submission = data['x_test']\n\nprint(f\"Numerical Data Loaded: {X_train_full.shape} samples\")\n\n# B. Load Original Data to Recover IDs\n# We need IDs to find the matching image for each row of numbers\ntry:\n    raw_df = pd.read_excel(ORIGINAL_DATA_PATH)\nexcept FileNotFoundError:\n    print(f\"‚ö†Ô∏è File not found at {ORIGINAL_DATA_PATH}. Searching for valid path...\")\n    for root, dirs, files in os.walk('/kaggle/input'):\n        for file in files:\n            if 'train' in file and '.xlsx' in file:\n                ORIGINAL_DATA_PATH = os.path.join(root, file)\n                print(f\"‚úÖ Found correct path: {ORIGINAL_DATA_PATH}\")\n                raw_df = pd.read_excel(ORIGINAL_DATA_PATH)\n                break\n\n# C. Align IDs with X_train_full\n# If X_train_full has 16209 rows, we need 16209 IDs.\nif len(raw_df) == len(X_train_full):\n    print(\"‚úÖ ID Count matches Data Count. Using IDs directly.\")\n    train_ids_full = raw_df['id'].values\nelse:\n    print(f\"‚ö†Ô∏è Size mismatch (DF: {len(raw_df)} vs X: {len(X_train_full)}). Re-splitting IDs...\")\n    # This assumes your preprocessing used random_state=42\n    _, _, _, _, train_ids_full, _ = train_test_split(\n        raw_df, raw_df['price'], raw_df['id'], test_size=0.2, random_state=42\n    )\n\n# D. Create Validation Split\n# We split everything (X, y, and IDs) together so they stay perfectly aligned\nX_train, X_val, y_train, y_val, train_ids, val_ids = train_test_split(\n    X_train_full, \n    y_train_full, \n    train_ids_full, \n    test_size=0.2, \n    random_state=42\n)\n\n# E. Log-Transform Targets (CRITICAL for RMSE)\ny_train_log = np.log1p(y_train)\ny_val_log = np.log1p(y_val)\n\nprint(f\"Final Training Set: {X_train.shape} samples\")\nprint(f\"Final Validation Set: {X_val.shape} samples\")\n\n# ==========================================\n# 3. DATASET CLASS & LOADERS\n# ==========================================\nclass RealEstateDataset(Dataset):\n    def __init__(self, features, ids, image_dir, targets=None, transform=None, mode='train'):\n        self.features = torch.tensor(features, dtype=torch.float32)\n        self.ids = [str(i) for i in ids] # Ensure string for filenames\n        self.image_dir = image_dir\n        self.transform = transform\n        self.mode = mode\n        \n        if mode == 'train':\n            self.targets = torch.tensor(targets, dtype=torch.float32).view(-1, 1)\n        else:\n            self.targets = None\n\n    def __len__(self):\n        return len(self.features)\n\n    def __getitem__(self, idx):\n        # 1. Load Image\n        img_id = self.ids[idx]\n        img_path = os.path.join(self.image_dir, f\"{img_id}.jpg\")\n        \n        try:\n            image = Image.open(img_path).convert('RGB')\n            if self.transform:\n                image = self.transform(image)\n        except (FileNotFoundError, OSError):\n            image = torch.zeros((3, 224, 224), dtype=torch.float32) # Fallback\n\n        # 2. Get Numbers\n        tab_data = self.features[idx]\n        \n        if self.mode == 'train':\n            return image, tab_data, self.targets[idx]\n        else:\n            return image, tab_data\n\n# Transforms\ntransform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\n\n# Create Loaders\ntrain_ds = RealEstateDataset(X_train, train_ids, IMAGE_DIR, y_train_log, transform, 'train')\nval_ds = RealEstateDataset(X_val, val_ids, IMAGE_DIR, y_val_log, transform, 'train')\n\ntrain_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\nval_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n\n# ==========================================\n# 4. MODEL ARCHITECTURE\n# ==========================================\nclass MultimodalNet(nn.Module):\n    def __init__(self, num_tabular_features):\n        super(MultimodalNet, self).__init__()\n        \n        # Image Branch\n        self.cnn = models.resnet18(pretrained=True)\n        self.cnn.fc = nn.Sequential(\n            nn.Linear(self.cnn.fc.in_features, 128),\n            nn.ReLU(),\n            nn.Dropout(0.3)\n        )\n        \n        # Tabular Branch\n        self.tabular_mlp = nn.Sequential(\n            nn.Linear(num_tabular_features, 64),\n            nn.ReLU(),\n            nn.Linear(64, 32),\n            nn.ReLU()\n        )\n        \n        # Fusion\n        self.fusion_head = nn.Sequential(\n            nn.Linear(128 + 32, 64),\n            nn.ReLU(),\n            nn.Dropout(0.2),\n            nn.Linear(64, 1)\n        )\n\n    def forward(self, image, tab_data):\n        img_embed = self.cnn(image)\n        tab_embed = self.tabular_mlp(tab_data)\n        combined = torch.cat((img_embed, tab_embed), dim=1)\n        return self.fusion_head(combined)\n\nmodel = MultimodalNet(num_tabular_features=X_train.shape[1]).to(DEVICE)\noptimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\ncriterion = nn.MSELoss()\n\n# ==========================================\n# 5. TRAINING LOOP\n# ==========================================\nprint(\"\\n--- Step 2: Training Model ---\")\nbest_rmse = float('inf')\n\nfor epoch in range(EPOCHS):\n    start_time = time.time()\n    model.train()\n    train_loss = 0\n    \n    # Train\n    for images, tabs, targets in train_loader:\n        images, tabs, targets = images.to(DEVICE), tabs.to(DEVICE), targets.to(DEVICE)\n        \n        optimizer.zero_grad()\n        outputs = model(images, tabs)\n        loss = criterion(outputs, targets)\n        loss.backward()\n        optimizer.step()\n        train_loss += loss.item()\n        \n    # Validate\n    model.eval()\n    actuals = []\n    predictions = []\n    \n    with torch.no_grad():\n        for images, tabs, targets in val_loader:\n            images, tabs = images.to(DEVICE), tabs.to(DEVICE)\n            \n            # Predict (Log Scale)\n            log_preds = model(images, tabs)\n            \n            # Convert back to Dollars\n            real_preds = torch.expm1(log_preds).cpu().numpy().flatten()\n            real_targets = torch.expm1(targets).cpu().numpy().flatten()\n            \n            predictions.extend(real_preds)\n            actuals.extend(real_targets)\n            \n    # Metrics\n    mse = np.mean((np.array(actuals) - np.array(predictions)) ** 2)\n    val_rmse = np.sqrt(mse)\n    val_r2 = r2_score(actuals, predictions)\n    \n    epoch_time = time.time() - start_time\n    print(f\"Epoch {epoch+1}/{EPOCHS} [{epoch_time:.0f}s] | RMSE: ${val_rmse:,.0f} | R¬≤: {val_r2:.4f}\")\n    \n    if val_rmse < best_rmse:\n        best_rmse = val_rmse\n        torch.save(model.state_dict(), 'best_multimodal_model.pth')\n        print(f\"   >>> üíæ Saved New Best Model!\")\n\nprint(f\"Training Complete. Best RMSE: ${best_rmse:,.0f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T05:28:37.355873Z","iopub.execute_input":"2026-01-08T05:28:37.356459Z","iopub.status.idle":"2026-01-08T05:30:19.696931Z","shell.execute_reply.started":"2026-01-08T05:28:37.356426Z","shell.execute_reply":"2026-01-08T05:30:19.695899Z"}},"outputs":[{"name":"stdout","text":"üöÄ Running on cuda\n\n--- Step 1: Loading Data ---\nNumerical Data Loaded: (16209, 18) samples\n‚úÖ ID Count matches Data Count. Using IDs directly.\nFinal Training Set: (12967, 18) samples\nFinal Validation Set: (3242, 18) samples\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"\n--- Step 2: Training Model ---\nEpoch 1/20 [50s] | RMSE: $403,626 | R¬≤: -0.2982\n   >>> üíæ Saved New Best Model!\nEpoch 2/20 [49s] | RMSE: $349,163 | R¬≤: 0.0285\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_55/1725167284.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    230\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mval_rmse\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mbest_rmse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m         \u001b[0mbest_rmse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_rmse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'best_multimodal_model.pth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    233\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"   >>> üíæ Saved New Best Model!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization, _disable_byteorder_record)\u001b[0m\n\u001b[1;32m    965\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_use_new_zipfile_serialization\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    966\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0m_open_zipfile_writer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 967\u001b[0;31m             _save(\n\u001b[0m\u001b[1;32m    968\u001b[0m                 \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    969\u001b[0m                 \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_save\u001b[0;34m(obj, zip_file, pickle_module, pickle_protocol, _disable_byteorder_record)\u001b[0m\n\u001b[1;32m   1264\u001b[0m                     \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_storage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1265\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1266\u001b[0;31m                     \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstorage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1267\u001b[0m             \u001b[0;31m# Now that it is on the CPU we can directly copy it into the zip file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1268\u001b[0m             \u001b[0mzip_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_record\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_bytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/storage.py\u001b[0m in \u001b[0;36mcpu\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    264\u001b[0m         \u001b[0;34m\"\"\"Return a CPU copy of this storage if it's not already on the CPU.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUntypedStorage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":31},{"cell_type":"code","source":"# Using XGBoost model to make the final predictions","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T05:30:37.760929Z","iopub.execute_input":"2026-01-08T05:30:37.761653Z","iopub.status.idle":"2026-01-08T05:30:37.765094Z","shell.execute_reply.started":"2026-01-08T05:30:37.761620Z","shell.execute_reply":"2026-01-08T05:30:37.764355Z"}},"outputs":[],"execution_count":32},{"cell_type":"code","source":"# 3. Initialize the Model\nmodel = xgb.XGBRegressor(\n    n_estimators=1000,\n    learning_rate=0.05,\n    max_depth=6,\n    subsample=0.8,\n    colsample_bytree=0.8,\n    n_jobs=-1,            # Use all CPU cores\n    random_state=42\n)\n\n# 4. Train with Early Stopping\n# This automatically stops if validation error stops dropping\neval_set = [(X_train, y_train), (X_val, y_val)]\n\nmodel.fit(\n    X_train, y_train,\n    eval_set=eval_set,\n    verbose=100  # Print progress every 100 rounds\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T05:30:54.668206Z","iopub.execute_input":"2026-01-08T05:30:54.668830Z","iopub.status.idle":"2026-01-08T05:30:56.629330Z","shell.execute_reply.started":"2026-01-08T05:30:54.668799Z","shell.execute_reply":"2026-01-08T05:30:56.628511Z"}},"outputs":[{"name":"stdout","text":"[0]\tvalidation_0-rmse:349592.54685\tvalidation_1-rmse:343051.15282\n[100]\tvalidation_0-rmse:91508.42621\tvalidation_1-rmse:125263.61970\n[200]\tvalidation_0-rmse:74581.65104\tvalidation_1-rmse:119568.82088\n[300]\tvalidation_0-rmse:65484.51287\tvalidation_1-rmse:117907.76656\n[400]\tvalidation_0-rmse:58709.92005\tvalidation_1-rmse:117363.64951\n[500]\tvalidation_0-rmse:53549.87199\tvalidation_1-rmse:116918.42573\n[600]\tvalidation_0-rmse:49414.45755\tvalidation_1-rmse:116785.66793\n[700]\tvalidation_0-rmse:45467.44412\tvalidation_1-rmse:116654.85252\n[800]\tvalidation_0-rmse:42127.67437\tvalidation_1-rmse:116590.62021\n[900]\tvalidation_0-rmse:39161.68013\tvalidation_1-rmse:116496.44823\n[999]\tvalidation_0-rmse:36537.00487\tvalidation_1-rmse:116523.57755\n","output_type":"stream"},{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"XGBRegressor(base_score=None, booster=None, callbacks=None,\n             colsample_bylevel=None, colsample_bynode=None,\n             colsample_bytree=0.8, device=None, early_stopping_rounds=None,\n             enable_categorical=False, eval_metric=None, feature_types=None,\n             feature_weights=None, gamma=None, grow_policy=None,\n             importance_type=None, interaction_constraints=None,\n             learning_rate=0.05, max_bin=None, max_cat_threshold=None,\n             max_cat_to_onehot=None, max_delta_step=None, max_depth=6,\n             max_leaves=None, min_child_weight=None, missing=nan,\n             monotone_constraints=None, multi_strategy=None, n_estimators=1000,\n             n_jobs=-1, num_parallel_tree=None, ...)","text/html":"<style>#sk-container-id-4 {\n  /* Definition of color scheme common for light and dark mode */\n  --sklearn-color-text: #000;\n  --sklearn-color-text-muted: #666;\n  --sklearn-color-line: gray;\n  /* Definition of color scheme for unfitted estimators */\n  --sklearn-color-unfitted-level-0: #fff5e6;\n  --sklearn-color-unfitted-level-1: #f6e4d2;\n  --sklearn-color-unfitted-level-2: #ffe0b3;\n  --sklearn-color-unfitted-level-3: chocolate;\n  /* Definition of color scheme for fitted estimators */\n  --sklearn-color-fitted-level-0: #f0f8ff;\n  --sklearn-color-fitted-level-1: #d4ebff;\n  --sklearn-color-fitted-level-2: #b3dbfd;\n  --sklearn-color-fitted-level-3: cornflowerblue;\n\n  /* Specific color for light theme */\n  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n  --sklearn-color-icon: #696969;\n\n  @media (prefers-color-scheme: dark) {\n    /* Redefinition of color scheme for dark theme */\n    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n    --sklearn-color-icon: #878787;\n  }\n}\n\n#sk-container-id-4 {\n  color: var(--sklearn-color-text);\n}\n\n#sk-container-id-4 pre {\n  padding: 0;\n}\n\n#sk-container-id-4 input.sk-hidden--visually {\n  border: 0;\n  clip: rect(1px 1px 1px 1px);\n  clip: rect(1px, 1px, 1px, 1px);\n  height: 1px;\n  margin: -1px;\n  overflow: hidden;\n  padding: 0;\n  position: absolute;\n  width: 1px;\n}\n\n#sk-container-id-4 div.sk-dashed-wrapped {\n  border: 1px dashed var(--sklearn-color-line);\n  margin: 0 0.4em 0.5em 0.4em;\n  box-sizing: border-box;\n  padding-bottom: 0.4em;\n  background-color: var(--sklearn-color-background);\n}\n\n#sk-container-id-4 div.sk-container {\n  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n     but bootstrap.min.css set `[hidden] { display: none !important; }`\n     so we also need the `!important` here to be able to override the\n     default hidden behavior on the sphinx rendered scikit-learn.org.\n     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n  display: inline-block !important;\n  position: relative;\n}\n\n#sk-container-id-4 div.sk-text-repr-fallback {\n  display: none;\n}\n\ndiv.sk-parallel-item,\ndiv.sk-serial,\ndiv.sk-item {\n  /* draw centered vertical line to link estimators */\n  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n  background-size: 2px 100%;\n  background-repeat: no-repeat;\n  background-position: center center;\n}\n\n/* Parallel-specific style estimator block */\n\n#sk-container-id-4 div.sk-parallel-item::after {\n  content: \"\";\n  width: 100%;\n  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n  flex-grow: 1;\n}\n\n#sk-container-id-4 div.sk-parallel {\n  display: flex;\n  align-items: stretch;\n  justify-content: center;\n  background-color: var(--sklearn-color-background);\n  position: relative;\n}\n\n#sk-container-id-4 div.sk-parallel-item {\n  display: flex;\n  flex-direction: column;\n}\n\n#sk-container-id-4 div.sk-parallel-item:first-child::after {\n  align-self: flex-end;\n  width: 50%;\n}\n\n#sk-container-id-4 div.sk-parallel-item:last-child::after {\n  align-self: flex-start;\n  width: 50%;\n}\n\n#sk-container-id-4 div.sk-parallel-item:only-child::after {\n  width: 0;\n}\n\n/* Serial-specific style estimator block */\n\n#sk-container-id-4 div.sk-serial {\n  display: flex;\n  flex-direction: column;\n  align-items: center;\n  background-color: var(--sklearn-color-background);\n  padding-right: 1em;\n  padding-left: 1em;\n}\n\n\n/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\nclickable and can be expanded/collapsed.\n- Pipeline and ColumnTransformer use this feature and define the default style\n- Estimators will overwrite some part of the style using the `sk-estimator` class\n*/\n\n/* Pipeline and ColumnTransformer style (default) */\n\n#sk-container-id-4 div.sk-toggleable {\n  /* Default theme specific background. It is overwritten whether we have a\n  specific estimator or a Pipeline/ColumnTransformer */\n  background-color: var(--sklearn-color-background);\n}\n\n/* Toggleable label */\n#sk-container-id-4 label.sk-toggleable__label {\n  cursor: pointer;\n  display: flex;\n  width: 100%;\n  margin-bottom: 0;\n  padding: 0.5em;\n  box-sizing: border-box;\n  text-align: center;\n  align-items: start;\n  justify-content: space-between;\n  gap: 0.5em;\n}\n\n#sk-container-id-4 label.sk-toggleable__label .caption {\n  font-size: 0.6rem;\n  font-weight: lighter;\n  color: var(--sklearn-color-text-muted);\n}\n\n#sk-container-id-4 label.sk-toggleable__label-arrow:before {\n  /* Arrow on the left of the label */\n  content: \"‚ñ∏\";\n  float: left;\n  margin-right: 0.25em;\n  color: var(--sklearn-color-icon);\n}\n\n#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {\n  color: var(--sklearn-color-text);\n}\n\n/* Toggleable content - dropdown */\n\n#sk-container-id-4 div.sk-toggleable__content {\n  max-height: 0;\n  max-width: 0;\n  overflow: hidden;\n  text-align: left;\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-4 div.sk-toggleable__content.fitted {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n#sk-container-id-4 div.sk-toggleable__content pre {\n  margin: 0.2em;\n  border-radius: 0.25em;\n  color: var(--sklearn-color-text);\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-4 div.sk-toggleable__content.fitted pre {\n  /* unfitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n  /* Expand drop-down */\n  max-height: 200px;\n  max-width: 100%;\n  overflow: auto;\n}\n\n#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n  content: \"‚ñæ\";\n}\n\n/* Pipeline/ColumnTransformer-specific style */\n\n#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-4 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Estimator-specific style */\n\n/* Colorize estimator box */\n#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-4 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n#sk-container-id-4 div.sk-label label.sk-toggleable__label,\n#sk-container-id-4 div.sk-label label {\n  /* The background is the default theme color */\n  color: var(--sklearn-color-text-on-default-background);\n}\n\n/* On hover, darken the color of the background */\n#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n/* Label box, darken color on hover, fitted */\n#sk-container-id-4 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Estimator label */\n\n#sk-container-id-4 div.sk-label label {\n  font-family: monospace;\n  font-weight: bold;\n  display: inline-block;\n  line-height: 1.2em;\n}\n\n#sk-container-id-4 div.sk-label-container {\n  text-align: center;\n}\n\n/* Estimator-specific */\n#sk-container-id-4 div.sk-estimator {\n  font-family: monospace;\n  border: 1px dotted var(--sklearn-color-border-box);\n  border-radius: 0.25em;\n  box-sizing: border-box;\n  margin-bottom: 0.5em;\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-4 div.sk-estimator.fitted {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n/* on hover */\n#sk-container-id-4 div.sk-estimator:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-4 div.sk-estimator.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Specification for estimator info (e.g. \"i\" and \"?\") */\n\n/* Common style for \"i\" and \"?\" */\n\n.sk-estimator-doc-link,\na:link.sk-estimator-doc-link,\na:visited.sk-estimator-doc-link {\n  float: right;\n  font-size: smaller;\n  line-height: 1em;\n  font-family: monospace;\n  background-color: var(--sklearn-color-background);\n  border-radius: 1em;\n  height: 1em;\n  width: 1em;\n  text-decoration: none !important;\n  margin-left: 0.5em;\n  text-align: center;\n  /* unfitted */\n  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n  color: var(--sklearn-color-unfitted-level-1);\n}\n\n.sk-estimator-doc-link.fitted,\na:link.sk-estimator-doc-link.fitted,\na:visited.sk-estimator-doc-link.fitted {\n  /* fitted */\n  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n  color: var(--sklearn-color-fitted-level-1);\n}\n\n/* On hover */\ndiv.sk-estimator:hover .sk-estimator-doc-link:hover,\n.sk-estimator-doc-link:hover,\ndiv.sk-label-container:hover .sk-estimator-doc-link:hover,\n.sk-estimator-doc-link:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\ndiv.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n.sk-estimator-doc-link.fitted:hover,\ndiv.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n.sk-estimator-doc-link.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\n/* Span, style for the box shown on hovering the info icon */\n.sk-estimator-doc-link span {\n  display: none;\n  z-index: 9999;\n  position: relative;\n  font-weight: normal;\n  right: .2ex;\n  padding: .5ex;\n  margin: .5ex;\n  width: min-content;\n  min-width: 20ex;\n  max-width: 50ex;\n  color: var(--sklearn-color-text);\n  box-shadow: 2pt 2pt 4pt #999;\n  /* unfitted */\n  background: var(--sklearn-color-unfitted-level-0);\n  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n}\n\n.sk-estimator-doc-link.fitted span {\n  /* fitted */\n  background: var(--sklearn-color-fitted-level-0);\n  border: var(--sklearn-color-fitted-level-3);\n}\n\n.sk-estimator-doc-link:hover span {\n  display: block;\n}\n\n/* \"?\"-specific style due to the `<a>` HTML tag */\n\n#sk-container-id-4 a.estimator_doc_link {\n  float: right;\n  font-size: 1rem;\n  line-height: 1em;\n  font-family: monospace;\n  background-color: var(--sklearn-color-background);\n  border-radius: 1rem;\n  height: 1rem;\n  width: 1rem;\n  text-decoration: none;\n  /* unfitted */\n  color: var(--sklearn-color-unfitted-level-1);\n  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n}\n\n#sk-container-id-4 a.estimator_doc_link.fitted {\n  /* fitted */\n  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n  color: var(--sklearn-color-fitted-level-1);\n}\n\n/* On hover */\n#sk-container-id-4 a.estimator_doc_link:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\n#sk-container-id-4 a.estimator_doc_link.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-3);\n}\n</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n             colsample_bylevel=None, colsample_bynode=None,\n             colsample_bytree=0.8, device=None, early_stopping_rounds=None,\n             enable_categorical=False, eval_metric=None, feature_types=None,\n             feature_weights=None, gamma=None, grow_policy=None,\n             importance_type=None, interaction_constraints=None,\n             learning_rate=0.05, max_bin=None, max_cat_threshold=None,\n             max_cat_to_onehot=None, max_delta_step=None, max_depth=6,\n             max_leaves=None, min_child_weight=None, missing=nan,\n             monotone_constraints=None, multi_strategy=None, n_estimators=1000,\n             n_jobs=-1, num_parallel_tree=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>XGBRegressor</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor\">?<span>Documentation for XGBRegressor</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n             colsample_bylevel=None, colsample_bynode=None,\n             colsample_bytree=0.8, device=None, early_stopping_rounds=None,\n             enable_categorical=False, eval_metric=None, feature_types=None,\n             feature_weights=None, gamma=None, grow_policy=None,\n             importance_type=None, interaction_constraints=None,\n             learning_rate=0.05, max_bin=None, max_cat_threshold=None,\n             max_cat_to_onehot=None, max_delta_step=None, max_depth=6,\n             max_leaves=None, min_child_weight=None, missing=nan,\n             monotone_constraints=None, multi_strategy=None, n_estimators=1000,\n             n_jobs=-1, num_parallel_tree=None, ...)</pre></div> </div></div></div></div>"},"metadata":{}}],"execution_count":33},{"cell_type":"code","source":"id = pd.read_csv('/kaggle/input/data-for-model-training-and-testing/test_ids.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T05:31:21.355413Z","iopub.execute_input":"2026-01-08T05:31:21.355916Z","iopub.status.idle":"2026-01-08T05:31:21.363701Z","shell.execute_reply.started":"2026-01-08T05:31:21.355875Z","shell.execute_reply":"2026-01-08T05:31:21.363058Z"}},"outputs":[],"execution_count":34},{"cell_type":"code","source":"predicted_price = model.predict(X_test_submit)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T05:31:44.470257Z","iopub.execute_input":"2026-01-08T05:31:44.470811Z","iopub.status.idle":"2026-01-08T05:31:44.550197Z","shell.execute_reply.started":"2026-01-08T05:31:44.470783Z","shell.execute_reply":"2026-01-08T05:31:44.549477Z"}},"outputs":[],"execution_count":35},{"cell_type":"code","source":"predicted_price = pd.DataFrame(predicted_price, columns=['predicted_price'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T05:32:24.815993Z","iopub.execute_input":"2026-01-08T05:32:24.816991Z","iopub.status.idle":"2026-01-08T05:32:24.821280Z","shell.execute_reply.started":"2026-01-08T05:32:24.816942Z","shell.execute_reply":"2026-01-08T05:32:24.820471Z"}},"outputs":[],"execution_count":36},{"cell_type":"code","source":"d = pd.concat([id,predicted_price],axis=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T05:33:48.805582Z","iopub.execute_input":"2026-01-08T05:33:48.806313Z","iopub.status.idle":"2026-01-08T05:33:48.810613Z","shell.execute_reply.started":"2026-01-08T05:33:48.806282Z","shell.execute_reply":"2026-01-08T05:33:48.809930Z"}},"outputs":[],"execution_count":38},{"cell_type":"code","source":"d","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T05:33:52.621166Z","iopub.execute_input":"2026-01-08T05:33:52.621471Z","iopub.status.idle":"2026-01-08T05:33:52.631036Z","shell.execute_reply.started":"2026-01-08T05:33:52.621445Z","shell.execute_reply":"2026-01-08T05:33:52.630229Z"}},"outputs":[{"execution_count":39,"output_type":"execute_result","data":{"text/plain":"              id  predicted_price\n0     2591820310     3.748754e+05\n1     7974200820     8.809516e+05\n2     7701450110     1.088302e+06\n3     9522300010     2.050641e+06\n4     9510861140     7.544586e+05\n...          ...              ...\n5399  7732500270     6.431563e+05\n5400  3856903515     6.638189e+05\n5401  2557000400     2.778444e+05\n5402  4386700135     2.013106e+06\n5403  7399000360     3.232961e+05\n\n[5404 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>predicted_price</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2591820310</td>\n      <td>3.748754e+05</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>7974200820</td>\n      <td>8.809516e+05</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>7701450110</td>\n      <td>1.088302e+06</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>9522300010</td>\n      <td>2.050641e+06</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>9510861140</td>\n      <td>7.544586e+05</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>5399</th>\n      <td>7732500270</td>\n      <td>6.431563e+05</td>\n    </tr>\n    <tr>\n      <th>5400</th>\n      <td>3856903515</td>\n      <td>6.638189e+05</td>\n    </tr>\n    <tr>\n      <th>5401</th>\n      <td>2557000400</td>\n      <td>2.778444e+05</td>\n    </tr>\n    <tr>\n      <th>5402</th>\n      <td>4386700135</td>\n      <td>2.013106e+06</td>\n    </tr>\n    <tr>\n      <th>5403</th>\n      <td>7399000360</td>\n      <td>3.232961e+05</td>\n    </tr>\n  </tbody>\n</table>\n<p>5404 rows √ó 2 columns</p>\n</div>"},"metadata":{}}],"execution_count":39},{"cell_type":"code","source":"# Making the submission csv","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T05:33:16.040559Z","iopub.execute_input":"2026-01-08T05:33:16.041312Z","iopub.status.idle":"2026-01-08T05:33:16.044827Z","shell.execute_reply.started":"2026-01-08T05:33:16.041273Z","shell.execute_reply":"2026-01-08T05:33:16.043931Z"}},"outputs":[],"execution_count":37},{"cell_type":"code","source":"import os\n\nos.makedirs('/kaggle/working/results', exist_ok=True)\nd.to_csv('/kaggle/working/results/predictions.csv', index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T05:33:58.795813Z","iopub.execute_input":"2026-01-08T05:33:58.796607Z","iopub.status.idle":"2026-01-08T05:33:58.810831Z","shell.execute_reply.started":"2026-01-08T05:33:58.796578Z","shell.execute_reply":"2026-01-08T05:33:58.810153Z"}},"outputs":[],"execution_count":40}]}